{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03010941, -0.00508483,  0.00243116, -0.04092926])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "abstract",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d9761596d5d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0maxleoffset\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, width, height, display)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_closed_by_user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, display, screen, config, context, mode)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mscreen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/canvas/base.py\u001b[0m in \u001b[0;36mget_default_screen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mScreen\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         '''\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_screens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyglet/canvas/base.py\u001b[0m in \u001b[0;36mget_screens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mScreen\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         '''\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'abstract'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_default_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: abstract"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MsPacman-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = env.render(mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MsPacman-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mspacman_color = np.array([210, 164, 74]).mean()\n",
    "\n",
    "def preprocess_observation(obs):\n",
    "    img = obs[1:176:2, ::2]\n",
    "    img = img.mean(axis=2)\n",
    "    img[img==mspacman_color] = 0\n",
    "    img = (img - 128) / 128 - 1\n",
    "    return img.reshape(88, 80, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess_observation(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method Viewer.__del__ of <gym.envs.classic_control.rendering.Viewer object at 0x10efcdef0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takahashishota/anaconda3/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\", line 143, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/takahashishota/anaconda3/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\", line 62, in close\n",
      "    self.window.close()\n",
      "AttributeError: 'Viewer' object has no attribute 'window'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApEAAAGdCAYAAABKASgtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEUQCAACgGEEkAAAAiv1/onOmg6bqVkMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fc68e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(11, 7))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Original observation (160×210 RGB)\")\n",
    "plt.imshow(obs)\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(122)\n",
    "plt.title(\"Preprocessed observation (88×80 greyscale)\")\n",
    "plt.imshow(img.reshape(88, 80), interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_height = 88\n",
    "input_width = 80\n",
    "input_channels = 1\n",
    "conv_n_maps = [32, 64, 64]\n",
    "conv_kernel_sizes = [(8,8), (4,4), (3,3)]\n",
    "conv_strides = [4, 2, 1]\n",
    "conv_paddings = [\"SAME\"] * 3 \n",
    "conv_activation = [tf.nn.relu] * 3\n",
    "n_hidden_in = 64 * 11 * 10  # conv3 has 64 maps of 11x10 each\n",
    "n_hidden = 512\n",
    "hidden_activation = tf.nn.relu\n",
    "n_outputs = env.action_space.n  # 9 discrete actions are available\n",
    "initializer = tf.variance_scaling_initializer()\n",
    "\n",
    "def q_network(X_state, name):\n",
    "    prev_layer = X_state / 128.0 # scale pixel intensities to the [-1.0, 1.0] range.\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        for n_maps, kernel_size, strides, padding, activation in zip(\n",
    "                conv_n_maps, conv_kernel_sizes, conv_strides,\n",
    "                conv_paddings, conv_activation):\n",
    "            prev_layer = tf.layers.conv2d(\n",
    "                prev_layer, filters=n_maps, kernel_size=kernel_size,\n",
    "                strides=strides, padding=padding, activation=activation,\n",
    "                kernel_initializer=initializer)\n",
    "        last_conv_layer_flat = tf.reshape(prev_layer, shape=[-1, n_hidden_in])\n",
    "        hidden = tf.layers.dense(last_conv_layer_flat, n_hidden,\n",
    "                                 activation=hidden_activation,\n",
    "                                 kernel_initializer=initializer)\n",
    "        outputs = tf.layers.dense(hidden, n_outputs,\n",
    "                                  kernel_initializer=initializer)\n",
    "    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                       scope=scope.name)\n",
    "    trainable_vars_by_name = {var.name[len(scope.name):]: var\n",
    "                              for var in trainable_vars}\n",
    "    return outputs, trainable_vars_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_state = tf.placeholder(tf.float32, shape=[None, input_height, input_width,\n",
    "                                            input_channels])\n",
    "online_q_values, online_vars = q_network(X_state, name=\"q_networks/online\")\n",
    "target_q_values, target_vars = q_network(X_state, name=\"q_networks/target\")\n",
    "\n",
    "copy_ops = [target_var.assign(online_vars[var_name])\n",
    "            for var_name, target_var in target_vars.items()]\n",
    "copy_online_to_target = tf.group(*copy_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/conv2d/bias:0': <tf.Variable 'q_networks/online/conv2d/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " '/conv2d/kernel:0': <tf.Variable 'q_networks/online/conv2d/kernel:0' shape=(8, 8, 1, 32) dtype=float32_ref>,\n",
       " '/conv2d_1/bias:0': <tf.Variable 'q_networks/online/conv2d_1/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " '/conv2d_1/kernel:0': <tf.Variable 'q_networks/online/conv2d_1/kernel:0' shape=(4, 4, 32, 64) dtype=float32_ref>,\n",
       " '/conv2d_2/bias:0': <tf.Variable 'q_networks/online/conv2d_2/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " '/conv2d_2/kernel:0': <tf.Variable 'q_networks/online/conv2d_2/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " '/dense/bias:0': <tf.Variable 'q_networks/online/dense/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " '/dense/kernel:0': <tf.Variable 'q_networks/online/dense/kernel:0' shape=(7040, 512) dtype=float32_ref>,\n",
       " '/dense_1/bias:0': <tf.Variable 'q_networks/online/dense_1/bias:0' shape=(9,) dtype=float32_ref>,\n",
       " '/dense_1/kernel:0': <tf.Variable 'q_networks/online/dense_1/kernel:0' shape=(512, 9) dtype=float32_ref>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.95\n",
    "\n",
    "with tf.variable_scope(\"train\"):\n",
    "    X_action = tf.placeholder(tf.int32, shape=[None])\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "    q_value = tf.reduce_sum(online_q_values * tf.one_hot(X_action, n_outputs),\n",
    "                            axis=1, keepdims=True)\n",
    "    error = tf.abs(y - q_value)\n",
    "    clipped_error = tf.clip_by_value(error, 0.0, 1.0)\n",
    "    linear_error = 2 * (error - clipped_error)\n",
    "    loss = tf.reduce_mean(tf.square(clipped_error) + linear_error)\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, maxlen):\n",
    "        self.maxlen = maxlen\n",
    "        self.buf = np.empty(shape=maxlen, dtype=np.object)\n",
    "        self.index = 0\n",
    "        self.length = 0\n",
    "        \n",
    "    def append(self, data):\n",
    "        self.buf[self.index] = data\n",
    "        self.length = min(self.length + 1, self.maxlen)\n",
    "        self.index = (self.index + 1) % self.maxlen\n",
    "    \n",
    "    def sample(self, batch_size, with_replacement=True):\n",
    "        if with_replacement:\n",
    "            indices = np.random.randint(self.length, size=batch_size) # faster\n",
    "        else:\n",
    "            indices = np.random.permutation(self.length)[:batch_size]\n",
    "        return self.buf[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory_size = 500000\n",
    "replay_memory = ReplayMemory(replay_memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_memories(batch_size):\n",
    "    cols = [[], [], [], [], []] # state, action, reward, next_state, continue\n",
    "    for memory in replay_memory.sample(batch_size):\n",
    "        for col, value in zip(cols, memory):\n",
    "            col.append(value)\n",
    "    cols = [np.array(col) for col in cols]\n",
    "    return cols[0], cols[1], cols[2].reshape(-1, 1), cols[3], cols[4].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_min = 0.1\n",
    "eps_max = 1.0\n",
    "eps_decay_steps = 2000000\n",
    "\n",
    "def epsilon_greedy(q_values, step):\n",
    "    epsilon = max(eps_min, eps_max - (eps_max-eps_min) * step/eps_decay_steps)\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(n_outputs) # random action\n",
    "    else:\n",
    "        return np.argmax(q_values) # optimal action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 4000000  # total number of training steps\n",
    "training_start = 10000  # start training after 10,000 game iterations\n",
    "training_interval = 4  # run a training step every 4 game iterations\n",
    "save_steps = 1000  # save the model every 1,000 training steps\n",
    "copy_steps = 10000  # copy online DQN to target DQN every 10,000 training steps\n",
    "discount_rate = 0.99\n",
    "skip_start = 90  # Skip the start of every game (it's just waiting time).\n",
    "batch_size = 50\n",
    "iteration = 0  # game iterations\n",
    "checkpoint_path = \"./my_dqn.ckpt\"\n",
    "done = True # env needs to be reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val = np.infty\n",
    "game_length = 0\n",
    "total_max_q = 0\n",
    "mean_max_q = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11956\tTraining step 489/4000000 (0.0)%\tLoss 0.757993\tMean Max-Q 0.043117   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6ec7204cc90d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             sample_memories(batch_size))\n\u001b[1;32m     48\u001b[0m         next_q_values = target_q_values.eval(\n\u001b[0;32m---> 49\u001b[0;31m             feed_dict={X_state: X_next_state_val})\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mmax_next_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_q_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcontinues\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiscount_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_next_q_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m     \"\"\"\n\u001b[0;32m--> 707\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5211\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5212\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5213\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_path + \".index\"):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "        copy_online_to_target.run()\n",
    "    while True:\n",
    "        step = global_step.eval()\n",
    "        if step >= n_steps:\n",
    "            break\n",
    "        iteration += 1\n",
    "        print(\"\\rIteration {}\\tTraining step {}/{} ({:.1f})%\\tLoss {:5f}\\tMean Max-Q {:5f}   \".format(\n",
    "            iteration, step, n_steps, step * 100 / n_steps, loss_val, mean_max_q), end=\"\")\n",
    "        if done: # game over, start again\n",
    "            obs = env.reset()\n",
    "            for skip in range(skip_start): # skip the start of each game\n",
    "                obs, reward, done, info = env.step(0)\n",
    "            state = preprocess_observation(obs)\n",
    "\n",
    "        # Online DQN evaluates what to do\n",
    "        q_values = online_q_values.eval(feed_dict={X_state: [state]})\n",
    "        action = epsilon_greedy(q_values, step)\n",
    "\n",
    "        # Online DQN plays\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        next_state = preprocess_observation(obs)\n",
    "\n",
    "        # Let's memorize what happened\n",
    "        replay_memory.append((state, action, reward, next_state, 1.0 - done))\n",
    "        state = next_state\n",
    "\n",
    "        # Compute statistics for tracking progress (not shown in the book)\n",
    "        total_max_q += q_values.max()\n",
    "        game_length += 1\n",
    "        if done:\n",
    "            mean_max_q = total_max_q / game_length\n",
    "            total_max_q = 0.0\n",
    "            game_length = 0\n",
    "\n",
    "        if iteration < training_start or iteration % training_interval != 0:\n",
    "            continue # only train after warmup period and at regular intervals\n",
    "        \n",
    "        # Sample memories and use the target DQN to produce the target Q-Value\n",
    "        X_state_val, X_action_val, rewards, X_next_state_val, continues = (\n",
    "            sample_memories(batch_size))\n",
    "        next_q_values = target_q_values.eval(\n",
    "            feed_dict={X_state: X_next_state_val})\n",
    "        max_next_q_values = np.max(next_q_values, axis=1, keepdims=True)\n",
    "        y_val = rewards + continues * discount_rate * max_next_q_values\n",
    "\n",
    "        # Train the online DQN\n",
    "        _, loss_val = sess.run([training_op, loss], feed_dict={\n",
    "            X_state: X_state_val, X_action: X_action_val, y: y_val})\n",
    "\n",
    "        # Regularly copy the online DQN to the target DQN\n",
    "        if step % copy_steps == 0:\n",
    "            copy_online_to_target.run()\n",
    "\n",
    "        # And save regularly\n",
    "        if step % save_steps == 0:\n",
    "            saver.save(sess, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "n_max_steps = 10000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "\n",
    "    obs = env.reset()\n",
    "    for step in range(n_max_steps):\n",
    "        state = preprocess_observation(obs)\n",
    "\n",
    "        # Online DQN evaluates what to do\n",
    "        q_values = online_q_values.eval(feed_dict={X_state: [state]})\n",
    "        action = np.argmax(q_values)\n",
    "\n",
    "        # Online DQN plays\n",
    "        obs, reward, done, info = env.step(action)\n",
    "\n",
    "        img = env.render(mode=\"rgb_array\")\n",
    "        frames.append(img)\n",
    "\n",
    "        if done:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
